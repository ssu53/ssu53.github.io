---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hello!
======

I am a PhD student in Computer Science at Stanford University, advised by [Serena Yeung-Levy](https://ai.stanford.edu/~syyeung/) and [Ludwig Schmidt](https://people.csail.mit.edu/ludwigs/). I am broadly interested in machine learning. 

I received an MPhil in Computer Science from the University of Cambridge, where I worked on learning over graphs with [Pietro Li√≤](https://www.cl.cam.ac.uk/~pl219/) and [Petar Veliƒçkoviƒá](https://petar-v.com/). Previously, I was a trader at [D. E. Shaw & Co.](https://www.deshaw.com/) and a physics major at Princeton University, studying condensed matter theory.


Research
======


* **Three Forms of Stochastic Injection for Improved Distribution-to-Distribution Generative Modeling**  
  Shiye Su, Yuhui Zhang, Linqi Zhou, Rajesh Ranganath, Serena Yeung-Levy  
  We identify sparse supervision as a key challenge in the distribution-to-distribution learning and improve performance using simple and effective perturbations during training.  
  [[paper]](https://arxiv.org/abs/2510.06634)

* **OpenThoughts: Data Recipes for Reasoning Models**  
  Etash Guha, Ryan Marten, Sedrick Keh, Negin Raoof, Georgios Smyrnis, Hritik Bansal, Marianna Nezhurina, Jean Mercat, Trung Vu, Zayne Sprague, Ashima Suvarna, Benjamin Feuer, Liangyu Chen, Zaid Khan, Eric Frankel, Sachin Grover, Caroline Choi, Niklas Muennighoff, Shiye Su, Wanjia Zhao, John Yang, Shreyas Pimpalgaonkar, Kartik Sharma, Charlie Cheng-Jie Ji, Yichuan Deng, Sarah Pratt, Vivek Ramanujan, Jon Saad-Falcon, Jeffrey Li, Achal Dave, Alon Albalak, Kushal Arora, Blake Wulfe, Chinmay Hegde, Greg Durrett, Sewoong Oh, Mohit Bansal, Saadia Gabriel, Aditya Grover, Kai-Wei Chang, Vaishaal Shankar, Aaron Gokaslan, Mike A. Merrill, Tatsunori Hashimoto, Yejin Choi, Jenia Jitsev, Reinhard Heckel, Maheswaran Sathiamoorthy, Alexandros G. Dimakis, Ludwig Schmidt  
  NeurIPS 2025, Workshop on Foundations of Reasoning in Language Models  
  We create open-source datasets for training reasoning models and investigate each step of the data geneartion pipeline with 1,000+ controlled experiments, yielding the state-of-the-art OpenThoughts3 model.  
  [[paper]](https://arxiv.org/abs/2506.04178)  

* **Generative Neural Networks for Kerr Combs**  
  Janet Zhong, Eran Lustig, Shiye Su, Louise Schul, Jamison Sloan, Congyue Deng, Jelena Vuckovic, Shanhui Fan  
  NeurIPS 2025, Machine Learning and the Physical Sciences Workshop  
  We apply generative modeling to the inverse design of Kerr micro-resonators, finding high-bandwidth steady-state solitons as given by Lugiato-Lefever equation simulations. 

* **Explaining Hypergraph Neural Networks: From Local Explanations to Global Concepts**  
  Shiye Su, Iulia Duta, Lucie Charlotte Magister, Pietro Li√≤  
  We design an architecture-agnostic, post-hoc method to produce faithful and concise explanations for hypergraph neural networks.  
  [[paper]](https://arxiv.org/abs/2410.07764)

* **Commute-Time-Optimised Graphs for GNNs**  
  Igor Sterner, Shiye Su, Petar Veliƒçkoviƒá  
  ICML 2024, GRaM workshop (PMLR)  
  We develop a graph rewiring procedure based on Cayley expanders, reducing oversquashing and incorporating user priors.  
  [[paper]](https://arxiv.org/abs/2407.08762)

* **ALMANACS: A Simulatability Benchmark for Language Model Explainability**  
  Edmund Mills, Shiye Su, Stuart Russell, Scott Emmons  
  We introduce a simulatability benchmark for language model interpretability, comprising structured, idiosyncratic questions with test-time distributional shift.  
  [[paper]](https://arxiv.org/abs/2312.12747)

* **Fitness Aware Human Motion Generation with Fine-Tuning**  
  Kiril Bikov, Shiye Su, Deepro Choudhury, Zhilin Guo, Weihao Xia, Mehmet Salih √áeliktenyƒ±ldƒ±z, Chenliang Zhou, Param Hanji, Cengiz Oztireli  
  NeurIPS 2025, FITML Workshop  
  We condition a human motion diffusion model on subject fitness, learning from a motion-capture dataset of graded Functional Movement Screen actions.  
  [[paper]](https://openreview.net/forum?id=BTSnh5YdeI)

* **Chaos and Measurement-Induced Criticality on Stabiliser Circuits**  
  Shiye Su  
  My undergraduate thesis was advised by [Sarang Gopalakrishnan](https://ece.princeton.edu/people/sarang-gopalakrishnan) and [David Huse](https://phy.princeton.edu/people/david-huse). We studied the entanglement transition in a many-body system evolving under Clifford gates and projective measurements, as well as the spectral and thermalisation properties of Clifford gates.  
  [[paper]](https://dataspace.princeton.edu/handle/88435/dsp01h989r6258)



Awards
======

* Stanford School of Engineering Fellowship, 2024
* Stanford EDGE Fellowship, 2024
* Open Philanthropy Scholarship, 2023


Miscellaneous
======

I am from Australia :) 
In 2023, I walked for one month from the French Pyrenees to Santiago de Compostela.
My first research project claims to find a heuristic for the Travelling Salesman Problem by tracking *C. Elegans* worms in chemotaxis. ü™±
